{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae31073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import loadMedicalMNIST as load_data\n",
    "import Model as neural_network\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9d57d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0  1\n",
      "0  Hand/001498.jpeg  0\n",
      "1  Hand/004360.jpeg  0\n",
      "2  Hand/005988.jpeg  0\n",
      "3  Hand/001162.jpeg  0\n",
      "4  Hand/009552.jpeg  0\n",
      "58954\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'Documents/datasets/MedicalMNIST'\n",
    "df = load_data.get_labels_df(root_dir)\n",
    "dataset = load_data.MedicalMNIST(df, root_dir, transform=load_data.data_transform())\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f160d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset,\n",
    "                                                   [48954,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37638f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe8a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the hyperparameters\n",
    "n_epochs = 10\n",
    "lr = 0.001\n",
    "in_channels = 3\n",
    "output_classes = 6\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, batch_size=(batch_size), shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=(batch_size), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1977be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 62, 62]             896\n",
      "         MaxPool2d-2           [-1, 32, 31, 31]               0\n",
      "            Conv2d-3           [-1, 16, 29, 29]           4,624\n",
      "         MaxPool2d-4           [-1, 16, 14, 14]               0\n",
      "           Flatten-5                 [-1, 3136]               0\n",
      "           Dropout-6                 [-1, 3136]               0\n",
      "            Linear-7                   [-1, 64]         200,768\n",
      "            Linear-8                    [-1, 6]             390\n",
      "================================================================\n",
      "Total params: 206,678\n",
      "Trainable params: 206,678\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.35\n",
      "Params size (MB): 0.79\n",
      "Estimated Total Size (MB): 2.18\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = neural_network.MNIST_CNN(in_channels, output_classes).to(device)\n",
    "print(summary(model,input_size = (3,64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48d16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss and the optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819b4ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Current Loss: tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "1 Current Loss: tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "2 Current Loss: tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "3 Current Loss: tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "4 Current Loss: tensor(3.1569e-06, grad_fn=<NllLossBackward0>)\n",
      "5 Current Loss: tensor(4.6934e-05, grad_fn=<NllLossBackward0>)\n",
      "6 Current Loss: tensor(4.4806e-07, grad_fn=<NllLossBackward0>)\n",
      "7 Current Loss: tensor(2.8177e-06, grad_fn=<NllLossBackward0>)\n",
      "8 Current Loss: tensor(3.0419e-07, grad_fn=<NllLossBackward0>)\n",
      "9 Current Loss: tensor(0.0040, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Train the network\n",
    "def train(model, n_epochs, train_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch, (data, targets) in enumerate(train_loader):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            \n",
    "            #Forward\n",
    "            scores = model(data)\n",
    "            loss = loss_function(scores, targets)\n",
    "            \n",
    "            #Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient descent\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(epoch, \"Current Loss:\", loss)\n",
    "train(model, n_epochs, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568f464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(99.2000) %\n"
     ]
    }
   ],
   "source": [
    "def evaluate(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, pred = scores.max(1)\n",
    "            correct += (pred == y).sum()\n",
    "            total += pred.size(0)\n",
    "        print(\"Accuracy:\", correct/total*100, \"%\")\n",
    "evaluate(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c5901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
